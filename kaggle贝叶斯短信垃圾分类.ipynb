{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle 垃圾短信分类，数据集https://www.kaggle.com/uciml/sms-spam-collection-dataset 参考:https://www.kaggle.com/pablovargas/naive-bayes-svm-spam-filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用朴素贝叶斯进行文本分类。学习文本处理（分词，停用词过滤），贝叶斯分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "延深：使用贝叶斯分类器进行中文邮件分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>as per your request 'melle melle (oru minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner!! as a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile 11 months or more? u r entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>i'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>adphone six chances to win cash! from 100 to 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>adphone urgent! you have won a 1 week free mem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>i've been searching for the right words to tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>i have a date on sunday with will!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>adweb xxxmobilemovieclub: to use your credit,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>oh k...i'm watching here:)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>eh u remember how 2 spell his name... yes i di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>fine if thatåõs the way u feel. thatåõs the wa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>adphone england v macedonia - dont miss the go...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2 Unnamed: 2  \\\n",
       "0    ham  go until jurong point, crazy.. available only ...        NaN   \n",
       "1    ham                      ok lar... joking wif u oni...        NaN   \n",
       "2   spam  free entry in 2 a wkly comp to win fa cup fina...        NaN   \n",
       "3    ham  u dun say so early hor... u c already then say...        NaN   \n",
       "4    ham  nah i don't think he goes to usf, he lives aro...        NaN   \n",
       "5   spam  freemsg hey there darling it's been 3 week's n...        NaN   \n",
       "6    ham  even my brother is not like to speak with me. ...        NaN   \n",
       "7    ham  as per your request 'melle melle (oru minnamin...        NaN   \n",
       "8   spam  winner!! as a valued network customer you have...        NaN   \n",
       "9   spam  had your mobile 11 months or more? u r entitle...        NaN   \n",
       "10   ham  i'm gonna be home soon and i don't want to tal...        NaN   \n",
       "11  spam  adphone six chances to win cash! from 100 to 2...        NaN   \n",
       "12  spam  adphone urgent! you have won a 1 week free mem...        NaN   \n",
       "13   ham  i've been searching for the right words to tha...        NaN   \n",
       "14   ham                i have a date on sunday with will!!        NaN   \n",
       "15  spam   adweb xxxmobilemovieclub: to use your credit,...        NaN   \n",
       "16   ham                         oh k...i'm watching here:)        NaN   \n",
       "17   ham  eh u remember how 2 spell his name... yes i di...        NaN   \n",
       "18   ham  fine if thatåõs the way u feel. thatåõs the wa...        NaN   \n",
       "19  spam  adphone england v macedonia - dont miss the go...        NaN   \n",
       "\n",
       "   Unnamed: 3 Unnamed: 4  \n",
       "0         NaN        NaN  \n",
       "1         NaN        NaN  \n",
       "2         NaN        NaN  \n",
       "3         NaN        NaN  \n",
       "4         NaN        NaN  \n",
       "5         NaN        NaN  \n",
       "6         NaN        NaN  \n",
       "7         NaN        NaN  \n",
       "8         NaN        NaN  \n",
       "9         NaN        NaN  \n",
       "10        NaN        NaN  \n",
       "11        NaN        NaN  \n",
       "12        NaN        NaN  \n",
       "13        NaN        NaN  \n",
       "14        NaN        NaN  \n",
       "15        NaN        NaN  \n",
       "16        NaN        NaN  \n",
       "17        NaN        NaN  \n",
       "18        NaN        NaN  \n",
       "19        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('D:/my/mldemo/emailcheck/data/spam.csv',encoding='latin-1')\n",
    "data['v2'] = data['v2'].str.lower()\n",
    "def filterdata(s):\n",
    "    numcount = len(re.findall(\"\\d+\", s))\n",
    "    strlen = len(s)\n",
    "    if numcount/strlen>0.05:\n",
    "        s = \"adphone \" + s \n",
    "    r = re.search(\"(http[s]?:\\/\\/)?[\\w\\d]+\\.\\s[\\w\\d]+\\.\\s*[\\w]+\",s,re.M|re.I)\n",
    "    if r!=None:\n",
    "        s = \" adweb \" + s  \n",
    "    return  s\n",
    "\n",
    "data['v2'] = data['v2'].apply(filterdata)\n",
    "data.head(n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words in non-spam</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>1665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>1544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>my</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>me</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>that</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>it</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>have</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>your</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>but</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>are</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>so</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   words in non-spam  count\n",
       "0                  i   2172\n",
       "1                you   1665\n",
       "2                 to   1544\n",
       "3                the   1113\n",
       "4                  a   1046\n",
       "5                  u    874\n",
       "6                and    845\n",
       "7                 in    786\n",
       "8                 my    741\n",
       "9                 is    710\n",
       "10                me    584\n",
       "11                of    518\n",
       "12               for    496\n",
       "13              that    442\n",
       "14                it    440\n",
       "15              have    433\n",
       "16              your    413\n",
       "17               but    413\n",
       "18               are    405\n",
       "19                so    399"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count1 = Counter(\" \".join(data[data['v1']=='ham'][\"v2\"]).split()).most_common(20) #查看正常短信中最常出现的20个词分别出现的次数，并用表格显示\n",
    "df1 = pd.DataFrame.from_dict(count1)\n",
    "df1 = df1.rename(columns={0: \"words in non-spam\", 1 : \"count\"})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words in non-spam</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>1665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>1544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>my</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>me</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>for</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>that</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>it</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>have</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>your</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>but</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>are</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>so</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   words in non-spam  count\n",
       "0                  i   2172\n",
       "1                you   1665\n",
       "2                 to   1544\n",
       "3                the   1113\n",
       "4                  a   1046\n",
       "5                  u    874\n",
       "6                and    845\n",
       "7                 in    786\n",
       "8                 my    741\n",
       "9                 is    710\n",
       "10                me    584\n",
       "11                of    518\n",
       "12               for    496\n",
       "13              that    442\n",
       "14                it    440\n",
       "15              have    433\n",
       "16              your    413\n",
       "17               but    413\n",
       "18               are    405\n",
       "19                so    399"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count2 = Counter(\" \".join(data[data['v1']=='spam'][\"v2\"]).split()).most_common(20) #查看垃圾短信中最常出现的20个词分别出现的次数\n",
    "df2 = pd.DataFrame.from_dict(count2)\n",
    "df2 = df1.rename(columns={0: \"words in non-spam\", 1 : \"count\"})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上可以看到常出现的词都是一些无意义的介词，虚词等，因此需要先去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "count  13.0\n",
       "mean    1.0\n",
       "std     0.0\n",
       "min     1.0\n",
       "25%     1.0\n",
       "50%     1.0\n",
       "75%     1.0\n",
       "max     1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用sklearn中CountVectoryzer获取文本特征，转化成一个向量形式，出现过的词为1，未出现的为0\n",
    "f = feature_extraction.text.CountVectorizer(stop_words = 'english') \n",
    "\n",
    "X = f.fit_transform(data[\"v2\"])\n",
    "## 看一下去除之后的内容\n",
    "a = pd.SparseDataFrame(X[0,:]).T\n",
    "a.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3733, 8406), (1839, 8406)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     ham\n",
       "1     ham\n",
       "2    spam\n",
       "3     ham\n",
       "4     ham\n",
       "5    spam\n",
       "6     ham\n",
       "7     ham\n",
       "8    spam\n",
       "9    spam\n",
       "Name: v1, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, data['v1'], test_size=0.33, random_state=42)\n",
    "print([np.shape(X_train), np.shape(X_test)])\n",
    "a =data[\"v1\"]\n",
    "a.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.998393</td>\n",
       "      <td>0.974986</td>\n",
       "      <td>0.924603</td>\n",
       "      <td>0.896154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.11001</td>\n",
       "      <td>0.997589</td>\n",
       "      <td>0.976618</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.891386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.22001</td>\n",
       "      <td>0.997857</td>\n",
       "      <td>0.978793</td>\n",
       "      <td>0.948413</td>\n",
       "      <td>0.901887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33001</td>\n",
       "      <td>0.997857</td>\n",
       "      <td>0.978249</td>\n",
       "      <td>0.948413</td>\n",
       "      <td>0.898496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.44001</td>\n",
       "      <td>0.997053</td>\n",
       "      <td>0.978249</td>\n",
       "      <td>0.948413</td>\n",
       "      <td>0.898496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.55001</td>\n",
       "      <td>0.996518</td>\n",
       "      <td>0.977705</td>\n",
       "      <td>0.948413</td>\n",
       "      <td>0.895131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.66001</td>\n",
       "      <td>0.996518</td>\n",
       "      <td>0.977705</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.898113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.77001</td>\n",
       "      <td>0.996250</td>\n",
       "      <td>0.977162</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.900763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.88001</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.977162</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.900763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.99001</td>\n",
       "      <td>0.995714</td>\n",
       "      <td>0.977162</td>\n",
       "      <td>0.932540</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.10001</td>\n",
       "      <td>0.995178</td>\n",
       "      <td>0.979337</td>\n",
       "      <td>0.932540</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.21001</td>\n",
       "      <td>0.995178</td>\n",
       "      <td>0.979337</td>\n",
       "      <td>0.932540</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.32001</td>\n",
       "      <td>0.994910</td>\n",
       "      <td>0.979880</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.924901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.43001</td>\n",
       "      <td>0.994910</td>\n",
       "      <td>0.981512</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.54001</td>\n",
       "      <td>0.994642</td>\n",
       "      <td>0.981512</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.65001</td>\n",
       "      <td>0.994642</td>\n",
       "      <td>0.982055</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.939759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.76001</td>\n",
       "      <td>0.994107</td>\n",
       "      <td>0.982055</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.939759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.87001</td>\n",
       "      <td>0.993839</td>\n",
       "      <td>0.982599</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.943548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.98001</td>\n",
       "      <td>0.993839</td>\n",
       "      <td>0.982055</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.946939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.09001</td>\n",
       "      <td>0.993571</td>\n",
       "      <td>0.981512</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.946721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha  Train Accuracy  Test Accuracy  Test Recall  Test Precision\n",
       "0   0.00001        0.998393       0.974986     0.924603        0.896154\n",
       "1   0.11001        0.997589       0.976618     0.944444        0.891386\n",
       "2   0.22001        0.997857       0.978793     0.948413        0.901887\n",
       "3   0.33001        0.997857       0.978249     0.948413        0.898496\n",
       "4   0.44001        0.997053       0.978249     0.948413        0.898496\n",
       "5   0.55001        0.996518       0.977705     0.948413        0.895131\n",
       "6   0.66001        0.996518       0.977705     0.944444        0.898113\n",
       "7   0.77001        0.996250       0.977162     0.936508        0.900763\n",
       "8   0.88001        0.995714       0.977162     0.936508        0.900763\n",
       "9   0.99001        0.995714       0.977162     0.932540        0.903846\n",
       "10  1.10001        0.995178       0.979337     0.932540        0.917969\n",
       "11  1.21001        0.995178       0.979337     0.932540        0.917969\n",
       "12  1.32001        0.994910       0.979880     0.928571        0.924901\n",
       "13  1.43001        0.994910       0.981512     0.928571        0.936000\n",
       "14  1.54001        0.994642       0.981512     0.928571        0.936000\n",
       "15  1.65001        0.994642       0.982055     0.928571        0.939759\n",
       "16  1.76001        0.994107       0.982055     0.928571        0.939759\n",
       "17  1.87001        0.993839       0.982599     0.928571        0.943548\n",
       "18  1.98001        0.993839       0.982055     0.920635        0.946939\n",
       "19  2.09001        0.993571       0.981512     0.916667        0.946721"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_alpha = np.arange(1/100000, 20, 0.11)\n",
    "score_train = np.zeros(len(list_alpha))\n",
    "score_test = np.zeros(len(list_alpha))\n",
    "recall_test = np.zeros(len(list_alpha))\n",
    "precision_test= np.zeros(len(list_alpha))\n",
    "count = 0\n",
    "for alpha in list_alpha:\n",
    "    bayes = naive_bayes.MultinomialNB(alpha=alpha)\n",
    "    bayes.fit(X_train, y_train)\n",
    "    score_train[count] = bayes.score(X_train, y_train)\n",
    "    score_test[count]= bayes.score(X_test, y_test)\n",
    "    recall_test[count] = metrics.recall_score(y_test, bayes.predict(X_test), average=\"binary\", pos_label=\"spam\")\n",
    "    precision_test[count] = metrics.precision_score(y_test, bayes.predict(X_test), average=\"binary\", pos_label=\"spam\")\n",
    "    count = count + 1 \n",
    "\n",
    "matrix = np.matrix(np.c_[list_alpha, score_train, score_test, recall_test, precision_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['alpha', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
    "models.head(n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha             15.620010\n",
       "Train Accuracy     0.980980\n",
       "Test Accuracy      0.970092\n",
       "Test Recall        0.781746\n",
       "Test Precision     1.000000\n",
       "Name: 142, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index = models['Test Precision'].idxmax()\n",
    "models.iloc[best_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
